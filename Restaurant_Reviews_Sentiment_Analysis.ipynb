{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1f18d7b-3255-429d-8294-7d734622aa6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.7\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe4120d5-6eb9-4399-b5b6-887cc276bd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import re\n",
    "from nltk.stem import SnowballStemmer #used for stemming\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, log_loss\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import matplotlib.pyplot as plt \n",
    "import spacy #used to identify aspects in the text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9a59517-c23b-411a-b22e-4f338c066f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Chris\\\\Documents\\\\Old_Laptop_Data\\\\Desktop\\\\College Work\\\\Intro to Machine Learning\\\\Final Project'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02d98190-105f-4805-9653-bb327c924b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Liked\n",
       "0                           Wow... Loved this place.      1\n",
       "1                                 Crust is not good.      0\n",
       "2          Not tasty and the texture was just nasty.      0\n",
       "3  Stopped by during the late May bank holiday of...      1\n",
       "4  The selection on the menu was great and so wer...      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:\\\\Users\\\\Chris\\\\Documents\\\\Old_Laptop_Data\\\\Desktop\\\\College Work\\\\Intro to Machine Learning\\\\Final Project\\\\Restaurant_Customer_Reviews\\\\Restaurant_Reviews.csv\", encoding='iso-8859-1')\n",
    "data.head()\n",
    "#If review is positive Liked = 1 and if review is negative Liked = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0536b475-d6dd-49df-baac-cb8993493e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.50025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Liked\n",
       "count  1000.00000\n",
       "mean      0.50000\n",
       "std       0.50025\n",
       "min       0.00000\n",
       "25%       0.00000\n",
       "50%       0.50000\n",
       "75%       1.00000\n",
       "max       1.00000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94f54b1c-ed23-4457-a4fb-14738a3d9dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 2 artists>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_zeros = len(data) - data['Liked'].sum()\n",
    "Liked = [0, 1]\n",
    "plt.bar(Liked, (num_zeros, data['Liked'].sum()), color='maroon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29581cbb-606f-4feb-b7d4-329783e083d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<transformers.models.bert.modeling_tf_bert.TFBertForSequenceClassification at 0x21e36fa3290>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'bert-large-uncased'#I chose bert-large-uncased because its more accurate than bert-base-uncased but more computationally expensive because it has more parameters to tune while bert-base-uncased is less accurate but less computationally expensive\n",
    "epochs = 5\n",
    "alpha = 0.01\n",
    "batch_size = 32\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = TFBertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a211da4-f16b-49cb-8317-c074f6e18ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of token_data_decode is:  wow loved this place\n",
      "Value of token_data_decode is now:  crust is not good\n",
      "Value of token_data_decode now is:  not tasty and the texture was just nasty\n",
      "Now the value of token_data_decode is:  stopped by during the late may bank holiday off rick steve recommendation and loved it\n",
      "And now the value of token_data_decode is:  the selection on the menu was great and so were the prices\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[101, 10166, 3866, 2023, 2173, 102]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[101, 19116, 2003, 2025, 2204, 102]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[101, 2025, 11937, 21756, 1998, 1996, 14902, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[101, 3030, 2011, 2076, 1996, 2397, 2089, 2924...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[101, 1996, 4989, 2006, 1996, 12183, 2001, 230...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>[101, 1045, 2228, 2833, 2323, 2031, 14894, 199...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>[101, 18923, 6880, 2908, 102]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>[101, 3452, 1045, 2001, 2025, 7622, 1998, 2052...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>[101, 1996, 2878, 3325, 2001, 2104, 2860, 2454...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>[101, 2059, 2004, 2065, 1045, 2910, 2102, 1384...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             input_ids\n",
       "0                  [101, 10166, 3866, 2023, 2173, 102]\n",
       "1                  [101, 19116, 2003, 2025, 2204, 102]\n",
       "2    [101, 2025, 11937, 21756, 1998, 1996, 14902, 2...\n",
       "3    [101, 3030, 2011, 2076, 1996, 2397, 2089, 2924...\n",
       "4    [101, 1996, 4989, 2006, 1996, 12183, 2001, 230...\n",
       "..                                                 ...\n",
       "995  [101, 1045, 2228, 2833, 2323, 2031, 14894, 199...\n",
       "996                      [101, 18923, 6880, 2908, 102]\n",
       "997  [101, 3452, 1045, 2001, 2025, 7622, 1998, 2052...\n",
       "998  [101, 1996, 2878, 3325, 2001, 2104, 2860, 2454...\n",
       "999  [101, 2059, 2004, 2065, 1045, 2910, 2102, 1384...\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest_len = 149\n",
    "token_arr = np.empty([5])\n",
    "column_name = ['input_ids']\n",
    "token_data = pd.DataFrame(columns=column_name)\n",
    "\n",
    "#Remove all punctuation and extra spaces from each restaurant review then tokenize each review and add it to dataset\n",
    "for i in range(len(data['Review'])):\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z0-9\\s]', '', data.loc[i, 'Review'])\n",
    "    clean_text = \" \".join(cleaned_text.split())\n",
    "    data.loc[i, 'Review'] = clean_text\n",
    "    token_text = tokenizer(data.loc[i, \"Review\"])\n",
    "    token_data.loc[i, 'input_ids'] = token_text['input_ids']\n",
    "\n",
    "    \n",
    "token_data_decode = tokenizer.decode(token_data.loc[0, 'input_ids'], skip_special_tokens=True)\n",
    "print(\"Value of token_data_decode is: \", token_data_decode)\n",
    "token_data_decode = tokenizer.decode(token_data.loc[1, 'input_ids'], skip_special_tokens=True)\n",
    "print(\"Value of token_data_decode is now: \", token_data_decode)\n",
    "token_data_decode = tokenizer.decode(token_data.loc[2, 'input_ids'], skip_special_tokens=True)\n",
    "print(\"Value of token_data_decode now is: \", token_data_decode)\n",
    "token_data_decode = tokenizer.decode(token_data.loc[3, 'input_ids'], skip_special_tokens=True)\n",
    "print(\"Now the value of token_data_decode is: \", token_data_decode)\n",
    "token_data_decode = tokenizer.decode(token_data.loc[4, 'input_ids'], skip_special_tokens=True)\n",
    "print(\"And now the value of token_data_decode is: \", token_data_decode)\n",
    "token_data\n",
    "#input_ids show the token_id #'s of each word, the token_type_ids show\n",
    "#token_type_ids are used to differentiate between different segments of text in a sentence\n",
    "#attention_masks show which words the tokenizer will pay attention to if it = 1 then it will pay attention to it if it = 0 then it won't pay attention to it\n",
    "#I train the model with attention masks because then it'll know which tokens to pay attention to and which ones to ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d57a3010-91dd-436a-a51e-34d2e84b808a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[101, 10166, 3866, 2023, 2173, 102]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[101, 19116, 2003, 2025, 2204, 102]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[101, 2025, 11937, 21756, 1998, 1996, 14902, 2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[101, 3030, 2011, 2076, 1996, 2397, 2089, 2924...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[101, 1996, 4989, 2006, 1996, 12183, 2001, 230...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>[101, 1045, 2228, 2833, 2323, 2031, 14894, 199...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>[101, 18923, 6880, 2908, 102]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>[101, 3452, 1045, 2001, 2025, 7622, 1998, 2052...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>[101, 1996, 2878, 3325, 2001, 2104, 2860, 2454...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>[101, 2059, 2004, 2065, 1045, 2910, 2102, 1384...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tokens  Liked\n",
       "0                  [101, 10166, 3866, 2023, 2173, 102]      1\n",
       "1                  [101, 19116, 2003, 2025, 2204, 102]      0\n",
       "2    [101, 2025, 11937, 21756, 1998, 1996, 14902, 2...      0\n",
       "3    [101, 3030, 2011, 2076, 1996, 2397, 2089, 2924...      1\n",
       "4    [101, 1996, 4989, 2006, 1996, 12183, 2001, 230...      1\n",
       "..                                                 ...    ...\n",
       "995  [101, 1045, 2228, 2833, 2323, 2031, 14894, 199...      0\n",
       "996                      [101, 18923, 6880, 2908, 102]      0\n",
       "997  [101, 3452, 1045, 2001, 2025, 7622, 1998, 2052...      0\n",
       "998  [101, 1996, 2878, 3325, 2001, 2104, 2860, 2454...      0\n",
       "999  [101, 2059, 2004, 2065, 1045, 2910, 2102, 1384...      0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.insert(1, 'tokens', token_data)\n",
    "data.drop('Review', axis=1, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93cc610f-7a69-4f77-af58-c72d699f5852",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['tokens']\n",
    "X = pad_sequences(X, padding='post')\n",
    "y = data['Liked']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27ff0df6-43c9-43e3-b380-bf16368e5070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "25/25 [==============================] - 161s 5s/step - loss: 7.2868 - accuracy: 0.5088 - val_loss: 7.6795 - val_accuracy: 0.3750\n",
      "Epoch 2/5\n",
      "25/25 [==============================] - 131s 5s/step - loss: 7.6658 - accuracy: 0.5312 - val_loss: 7.6795 - val_accuracy: 0.3750\n",
      "Epoch 3/5\n",
      "25/25 [==============================] - 130s 5s/step - loss: 7.3453 - accuracy: 0.5088 - val_loss: 3.1924 - val_accuracy: 0.6250\n",
      "Epoch 4/5\n",
      "25/25 [==============================] - 129s 5s/step - loss: 6.6994 - accuracy: 0.4688 - val_loss: 7.6795 - val_accuracy: 0.6250\n",
      "Epoch 5/5\n",
      "25/25 [==============================] - 133s 5s/step - loss: 7.6658 - accuracy: 0.4688 - val_loss: 7.6795 - val_accuracy: 0.6250\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_history = model.fit(x_train, y_train, batch_size, epochs, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e0fdb7b-9686-443b-a673-a35c8e69db2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of training accuracy is:  0.58125\n",
      "Value of training loss is:  0.6495489814214019\n",
      "Value of validation accuracy is:  0.4\n",
      "Value of validation loss is:  0.8476893256017405\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(solver='liblinear', random_state=42)\n",
    "log_reg.fit(x_train, y_train)\n",
    "y_proba = log_reg.predict(x_test)\n",
    "train_acc = log_reg.score(x_train, y_train)#Get training accuracy\n",
    "print(\"Value of training accuracy is: \", train_acc)\n",
    "train_loss = log_loss(y_train, log_reg.predict_proba(x_train))#Get training loss\n",
    "print(\"Value of training loss is: \", train_loss)\n",
    "accuracy = accuracy_score(y_test, y_proba)#Get validation accuracy\n",
    "print(\"Value of validation accuracy is: \", accuracy)\n",
    "valid_loss = log_loss(y_test, log_reg.predict_proba(x_test))\n",
    "print(\"Value of validation loss is: \", valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "72b2925b-aa65-47af-9665-60c668c158ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 35)\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 1s 19ms/step - loss: 0.6935 - accuracy: 0.5063 - val_loss: 0.7021 - val_accuracy: 0.3750\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6918 - accuracy: 0.5312 - val_loss: 0.7097 - val_accuracy: 0.3750\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6917 - accuracy: 0.5312 - val_loss: 0.7069 - val_accuracy: 0.3750\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6914 - accuracy: 0.5312 - val_loss: 0.7095 - val_accuracy: 0.3750\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6915 - accuracy: 0.5312 - val_loss: 0.7126 - val_accuracy: 0.3750\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6912 - accuracy: 0.5312 - val_loss: 0.7108 - val_accuracy: 0.3750\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6916 - accuracy: 0.5312 - val_loss: 0.7034 - val_accuracy: 0.3750\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6913 - accuracy: 0.5312 - val_loss: 0.7062 - val_accuracy: 0.3750\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6908 - accuracy: 0.5312 - val_loss: 0.7084 - val_accuracy: 0.3750\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6883 - accuracy: 0.5312 - val_loss: 0.7095 - val_accuracy: 0.3750\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 30000  # Number of unique words to consider\n",
    "max_len = 100  # Maximum length of each review (padding/truncation)\n",
    "\n",
    "print(x_train.shape)\n",
    "rnn_model = keras.models.Sequential([                        \n",
    "    keras.layers.Embedding(input_dim=vocab_size, output_dim=32, input_length=35),   # Embedding layer  \n",
    "    keras.layers.SimpleRNN(64, dropout=0.3, activation=\"relu\"),                    #RNN layer, hidden vector size 64\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")                       #Output layer, binary classification with 1 neuron and sigmoid\n",
    "])\n",
    "\n",
    "rnn_model.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\", metrics=[\"accuracy\"])\n",
    "rnn_history = rnn_model.fit(x_train, y_train, epochs=10, batch_size=64, validation_data=(x_test, y_test))#validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19155a2-e70f-4098-827a-7f117e85d227",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
